%
\documentclass{beamer}
\setbeamersize{text margin left=0.4cm, text margin right=0.4cm}
%\usetheme{Boadilla}
\usetheme{Madrid}
\setbeamertemplate{theorems}[numbered]
\usepackage{amscd}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyhdr}
\usepackage{latexsym}
\usepackage{lmodern}
\usepackage{cancel}
\usepackage{hyperref}
%\synctex=1    synctex doesn't work with beamer
\usepackage{pdfsync}
\numberwithin{equation}{section}
%
\newcommand{\bigno}{\bigskip\noindent}
\newcommand{\ds}{\displaystyle}
\newcommand{\medno}{\medskip\noindent}
\newcommand{\smallno}{\smallskip\noindent}
\newcommand{\nin}{\noindent}
\newcommand{\ts}{\textstyle}
\newcommand{\rr}{\mathbb{R}}
\newcommand{\p}{\partial}
\newcommand{\zz}{\mathbb{Z}}
\newcommand{\cc}{\mathbb{C}}
\newcommand{\ci}{\mathbb{T}}
\newcommand{\tor}{\mathbb{T}}
\newcommand{\ee}{\varepsilon}
\newcommand{\wh}{\widehat}
\newcommand{\weak}{\rightharpoonup}
\newcommand{\vp}{\varphi}
%
%
\newtheorem{proposition}{Proposition}
\newtheorem{claim}{Claim}
\newtheorem{remark}{Remark}
\newtheorem{conjecture}[subsection]{conjecture}

%% Equation Numbers %%





%%%%%%%%%%%%%%%%%%%%%%
%
\date{03/30/2011}
\title
{ Well-posedness of  periodic NLS  \\in  analytic  spaces}
  
\author{{A.  Himonas,\, D. Karapetyan   \& G. Petronilho}}
%\author{Alex Himonas}
%\address{Department of Mathematics  \\
%       University of Notre Dame     \\
%         Notre Dame, IN 46556}

\begin{document}

\begin{frame}
\titlepage
\end{frame}


\section*{Table of Contents}
\begin{frame}
\frametitle{Table Of Contents}
\tableofcontents
\end{frame}
%
%
\begin{frame}
  \frametitle{Cubic NLS}
%
%
\begin{align*}
	&i \p_t u + \p_x^{2} u \pm
  |u|^2 u =0, \quad x\in \mathbb{T},\,\,t\in \mathbb{R}
		\\
		&u(x,0) = \vp(x).
\end{align*}
%
Some Introductory Material on the history of the equation.
\end{frame}
%
%
\section{The Analytic Spaces}
\begin{frame}
  \frametitle{The Analytic Spaces}
For $\delta >0$ and $s\ge 0$, we define 
\pause
%
%
\begin{align*}
 & G^{\delta,s}(\mathbb{T})=\{v\in L^2(\mathbb{T}):
 ||v||_{G^{\delta,s}(\mathbb{T})}< \infty \}
 \\
 & \| v \|_{G^{\delta,s}}
 =\left( \sum_{k\in \mathbb{Z}} 
 (1+ |k|)^{2s}e^{2\delta|k|}|\widehat{v}(k)|^2<\infty\right)^{1/2}
 \end{align*}
%
%
\pause
\begin{align*}
  & X_{\delta,s}=X_{\delta,s}(\mathbb{T}\times \mathbb{R})=\{v\in L^2(\mathbb{T}\times \mathbb{R}):
||v||_{X_{\delta,s}}<\infty\}
\\
& \| v \|_{X_{\delta,s}}
=\left( \sum_{k\in \mathbb{Z}}\int_{\mathbb{R}}(1+|\lambda
-k^2|)(1+|k|)^{2s}
e^{2\delta |k|}|\widehat{v}(k,\lambda)|^2d\lambda\right)^{1/2}.
\end{align*}
%
\pause
%
\begin{align*}
& Y_{\delta,s}=Y_{\delta,s}(\mathbb{T}\times \mathbb{R})=\{v\in L^2(\mathbb{T}\times \mathbb{R}):
||v||_{Y_{\delta,s}}<\infty\}
\\
& \| v \|_{Y_{\delta,s}}
= \|v \|_{X_{\delta,s}}
+\left [\sum_{k\in \mathbb{Z}}(1+|k|)^{2s}e^{2\delta |k|}
\left (\int_{\mathbb{R}}
|\widehat{v}(k,\lambda)|d\lambda \right)^2 \right]^{\frac{1}{2}} 
\end{align*}
%
\end{frame}
%
%
\begin{frame}
  \frametitle{Important Facts}
      \begin{lemma}
    If $\vp \in G^{\delta,s}(\ci)$, $s \ge 0$,
      then it is real analytic on all of $\ci$, with a complex
  analytic extension to a symmetric strip around the real axis with width $\delta$.
\end{lemma}
  \begin{lemma}We have the continuous embedding
$$Y_{\delta,s}(\mathbb{T}\times \mathbb{R})
\subset C([0,T],G^{\delta,s}(\mathbb{T})).$$
\end{lemma}
\end{frame}
%
%
\section{Main Result}
\begin{frame}
  \frametitle{Main Result}
%
\begin{theorem}
  \begin{enumerate}
%
\item
Let $s\ge 0$. For initial data in $G^{\delta,s}(\mathbb{T})$, $\delta >0$,
there exists a positive time $T$ such that the NLS initial-value problem
is well-posed in the space $C([0,T], G^{\delta,s}(\mathbb{T}))$.
%
\item
Moreover, the regularity of solutions in the time variable is of order Gevrey
two ($G^2$).
\end{enumerate}
%
\end{theorem}
\end{frame}
%
\begin{frame}
  \frametitle{NLS Localized Integral Form}
\begin{equation*}
  \begin{split}
u(x,t) & =
 \psi(t) \underset{n\in \mathbb{Z}}{\sum} e^{i(nx +n^2t)}  \widehat{\varphi} (n)
\\
& + \psi(t) \underset{n\in \mathbb{Z}}{\sum} e^{i(nx+n^2t)}  \int_{\mathbb{R}}
\frac{e^{i(\lambda-n^2 )t}-1}{\lambda-n^2}
\widehat{w}(n,\lambda) \ d \lambda
\end{split}
\end{equation*}
where $w=|u|^2\overline{u}=u\overline{u}u$ and 
$\psi$ is a cutoff function symmetric about the origin with
$\psi(t)=1$ for $| t | \le T$. Computing the $Y_{\delta,s}$ norm of the right
hand side, the proof of well-posedness reduces to showing the following.
\end{frame}
\subsection{Trilinear Estimates}
\begin{frame}
  \frametitle{Trilinear Estimates}
\begin{lemma}\label{bilinear1}
 For $s\ge 0$ and all $f, g, h \in Y_{\delta,s}$
 \begin{enumerate}
   \item
 \begin{align*}
   & \left ( \sum_{n \in {\mathbb{Z}}} (1+|n|)^{2s}e^{2\delta |n|}
\int_{\mathbb{R}}
\frac{|\widehat{w_{fgh}}(n, \lambda)|^2}{1+|\lambda -n^2|}
d\lambda
\right )^{1/2}
\\
& \lesssim \|f\|_{X_{\delta,s}} \|g\|_{X_{\delta,
s}}\|h\|_{X_{\delta,s}} 
\end{align*}
\item
\begin{align*}
& \left( \sum_{n \in \zz} \left (1 + |n| \right )^{2s} e^{2\delta |n|} \left (
\int_\rr \frac{|\wh{w_{fgh}}(n, \lambda) |}{1 + | \lambda - n^{2} |} \ d\lambda
\right)^2  \right)^{1/2}
\\
& \lesssim \|f\|_{X_{\delta,s}} \|g\|_{X_{1, \delta,
s}}\|h\|_{X_{\delta,s}}
\end{align*}
\end{enumerate}
\end{lemma}
\end{frame}
%
%
\begin{frame}
  \frametitle{Key Idea in Proof}
We will prove only the first trilinear estimate. The proof of the second is
similar. Start by setting
\begin{equation*}
c_u(n,\lambda)=|n|^s e^{\delta |n|}(1+|\lambda-n^2|)^{1/2}\widehat{u}(n,\lambda)
\end{equation*}
then we have
\begin{equation*}
||u||_{{X}_{\delta,s}}=\Big (\sum_{n\in \mathbb{{Z}}}\int_{\mathbb{R}}|c_u(n,\lambda)|^2d\lambda \Big )^{1/2}
=\| c_u(n,\lambda) \|_{l^2_n L^2_{\lambda}}.
\end{equation*}
\end{frame}
\begin{frame}
It follows that

\begin{eqnarray*}
&&\sum_{n } (1+|n|)^{2s}e^{2\delta |n|}
\int_{}
     \frac{|\widehat{w}(n, \lambda)|^2}{1+|\lambda -n^2|}
d\lambda
\\
&&
=\sum_{n  {}} (1+|n|)^{2s}e^{2\delta |n|}
\int_{}
     \frac{1}{1+|\lambda -n^2|}\Big \vert 
         \notag\\
&&
  \times  \sum_{n_1 {}}
     \int_{_{\lambda_1}}\sum_{n_2 {}}
     \int_{_{\lambda_2}}\frac{e^{-\delta |n-n_1|}c_u(n-n_1,\lambda-\lambda_1)}{(1+|n-n_1|)^s(1+|\lambda-\lambda_1-(n-n_1)^2|)^{1/2}}\notag\\
&&\times
\frac{e^{-\delta|n_1-n_2|}c_u(n_1-n_2,\lambda_1-\lambda_2)}{(1+|n_1-n_2|)^s(1+|\lambda_1-\lambda_2-(n_1-n_2)^2|)^{1/2}}
\\
&& \times \frac{e^{-\delta |n_2|}\overline{c_u(-n_2,-\lambda_2)}}{(1+|n_2|)^s(1+|\lambda_2+n_2^2|)^{1/2}}
d\lambda_2d\lambda_1 \Big \vert^2d\lambda
     \notag\\
   \end{eqnarray*}
   which is bounded by
 \end{frame}
   \begin{frame}
     \begin{eqnarray*}
      &&=\sum_{n  {}} 
\int_{\lambda}
     \Big \vert \sum_{n_1 {}}
     \int_{_{\lambda_1}}\sum_{n_2 {}}
     \int_{_{\lambda_2}}
     \\
     && \frac{(1 + |n|)^{s}|(1 + |n-n_1|)^{-s}(1 + |n_1-n_2|)^{-s}(1 + |n_2|)^{-s}}{(1+|\lambda -n^2|)^{1/2}(1+|\lambda-\lambda_1-(n-n_1)^2|)^{1/2}}\\
     &&\times \frac{c_u(n-n_1,\lambda-\lambda_1)c_u(n_1-n_2,\lambda_1-\lambda_2)\overline{c_u(-n_2,-\lambda_2)}}{(1+|\lambda_1-\lambda_2-(n_1-n_2)^2|)^{1/2}
     (1+|\lambda_2+n_2^2|)^{1/2}}d\lambda_1d\lambda_2 \Big \vert^2
\end{eqnarray*}
since $|n|\le |n-n_1|+ |n_1-n_2|+|n_2|$. This can be rewritten as
\begin{equation*}
  \sum_{n \in {\mathbb{Z}}} (1+|n|)^{2s}
\int_{\mathbb{R}}
\frac{|\widehat{w_{\tilde{f}\tilde{g}\tilde{h}}}(n, \lambda)|^2}{1+|\lambda -n^2|}
d\lambda
\end{equation*}
where
%
%
\begin{equation*}
\begin{split}
  \tilde{v}(x,t) = \left[ e^{\delta | n |} \wh{v}(n, \lambda) \right]^{\vee}.
\end{split}
\end{equation*}
%
%
From here the proof is the same as the NLS trilinear estimate. \qed
\end{frame}
\section{Regularity of Solutions in Time}
\begin{frame}
  \frametitle{Regularity of Solutions in Time}
%
%
%
\begin{proposition}
\label{fderivative}
Let  $u(x,t)$ be the solution to the cubic NLS 
with initial data  $\varphi\in G^{\delta, s}(\mathbb{T})$. 
Then
 %
\begin{equation*}
 \left |
\partial_t^j\partial_x^k u(x,t)\right | \leq
C^{k+j+1}(k+2j)! C^j,\,\,j\in \{0,1,2,\dots\},\,k
\in \{0,1,2\dots\}
\end{equation*}
for all $(x,t)\in \mathbb{T}\times [0,T]$.
\end{proposition}
\end{frame}
%
%
\begin{frame}
%
%
\begin{remark}
Note that the proposition implies Gevrey two regularity in space for $t \in
[0, T]$. To see this, set $j = 0$. We claim that
%
%
\begin{equation*}
\begin{split}
(2k)!
& \le 4^{k} (k!)^{2}, \quad k \ge 1
\end{split}
\end{equation*}
%
%
\pause
which we prove by induction. The inequality for the base case $k=1$ is clearly
true. For the inductive step, we assume the above inequality for $k' \le k$. Then
%
%
\begin{equation*}
\begin{split}
[2(k+1)]!
& = (2k+2)(2k+1)(2k)! 
\\
& \le (2k+2)(2k+1)4^{k}(k!)^{2}
\\
& \le (2k+2)^{2}4^{k}(k!)^{2}
\\
& = 4^{k+1} [(k+1)!]^{2}
\end{split}
\end{equation*}
%
%
which completes the proof. \qed
\label{rem:implication-gev}
\end{remark}
%
%
\end{frame}
\begin{frame}
  \frametitle{Base Case for Regularity Proposition}
The proof will be
done by induction. The base case $j=0$ and $k\in \{0,1,\dots \}$ 
is covered by the fact that $u(t) \in G^{\delta, s}(\mathbb{T})$ for $t \in
[0, T]$. Hence, $u(t)$ is real analytic on $\ci$ for $t \in [0, T]$. Therefore, there
exists $C>0$ such that 
%
\begin{equation*}
|\partial_x^\ell u(x,t)|\leq
C^{\ell+1}\ell!,\,\,\,\forall\,\,x\in \mathbb{T}, \ t \in [0, T].
\end{equation*}
\end{frame}
%
%
\begin{frame}
  \frametitle{Inductive Step}
Next we assume that the
inequality we seek to prove holds for $0\le \mu \le j$ and $k\in \{0,1,\dots\}$
and will prove it for $\mu =j+1$ and $k\in \{0,1,\dots\}$.
%
We begin by noticing that
%
\begin{equation*}
|\partial_t^{j+1}\partial_x^k u| = |\partial_t^j\partial_x^k
(i u^2\overline{u})+i\partial_t^j\partial_x^{k+2}u| \le
|\partial_t^j\partial_x^k
(u^2\overline{u})|+|\partial_t^j\partial_x^{k +2}u|.
\end{equation*}
%
Using the induction hypothesis we estimate the second  term
$\partial_t^j\partial_x^{k +2}u$ as follows
%
\begin{eqnarray*}
|\partial_t^j\partial_x^{k +2}u|&\le&
C^{k+j+3}(k+2+2 j)! C^j\notag\\
& \le &C^{k+j+2}[k+2(j+1)]! C^{j+1}.
\end{eqnarray*}
%
\end{frame}
\begin{frame}
  \frametitle{Estimating the Nonlinear Term}
 Next, we estimate  the non-linear term $\partial_t^j\partial_x^k (u^2\overline{u})$.
Using Leibniz's formula  we can write
%
\begin{align*}
& \partial_t^j\partial_x^k (u^2 \overline{u})
\\
& = \sum_{p_1=0}^k\sum_{p_2=0}^{p_1}
\sum_{j_1=0}^j\sum_{j_2=0}^{j_1}\binom{k}{p_1}\binom{p_1}{p_2}
\binom{j}{j_1}\binom{j_1}{j_2}
\partial_t^{j-j_1}\partial_x^{k-p_1}u
\partial_t^{j_1-j_2}\partial_x^{p_1-p_2}u
 \partial_t^{j_2}
\partial_x^{p_2}\overline{u}.\notag
\end{align*}
%
Thus, using  the induction hypothesis  the last equality gives
%
\begin{eqnarray*}
\left \vert \partial_t^j\partial_x^k (u^2 \overline{u})\right \vert
&\le&\sum_{p_1=0}^k\sum_{p_2=0}^{p_1}
\sum_{j_1=0}^j\sum_{j_2=0}^{j_1}\binom{k}{p_1}\binom{p_1}{p_2}
\binom{j}{j_1}\binom{j_1}{j_2}\notag\\
&\times&C^{k-p_1+j-j_1+1}[k-p_1+2(j-j_1)]!C^{j-j_1}\notag\\
&\times&C^{p_1-p_2+j_1-j_2+1}[p_1-p_2+2(j_1-j_2)]!C^{j_1-j_2}\notag\\
&\times&C^{p_2+j_2+1}[p_2+2j_2]!C^{j_2}.\notag
\end{eqnarray*}
%
\end{frame}
%
%
\subsection{Key Combinatorial Lemma}
\begin{frame}
  \frametitle{Key Combinatorial Lemma}
  \begin{lemma}
For given $\ell, k\in \{0,1,2,\cdots\}$ and  $\theta=\ell+ 2k$ we have
%
\begin{equation*}
\label{key-in} \sum_{p=0}^{\ell}
\sum_{q=0}^{k}\binom{\ell}{p}\binom{k}{q}[\ell-p+2(k-q)]!
(p+2 q)!\le (\theta+1)\theta!.
\end{equation*}
%
\end{lemma}
\end{frame}
%
%
\begin{frame}
 %
Applying the lemma, we get 
 %
\begin{equation*}
\label{meq7}
\begin{split}
\left \vert \partial_t^j\partial_x^k (u^2\overline{u})\right \vert
&\le C^{k+j + 2}(k+2j)!
(k+2j+1)C^{j+1}\\
&\le C^{k+j+2}[k+2(j+1)]! C^{j+1}.
\end{split}
\end{equation*}
%
completing the proof. \qed
\end{frame}
\section{Appendix}
\subsection{Proof of Combinatorial Lemma} 
\label{ssec:proof-comb}
\begin{frame}
  \frametitle{Appendix: Proof of Combinatorial Lemma}
 For $\ell, k\in \{0,1,2,\cdots\}$  given
let  $\theta=\ell+2k$. Then, changing the order of
the summations and making a change of variable gives
%
%
\begin{equation*}
\begin{split}
&\sum_{p=0}^{\ell}
\sum_{q=0}^{k}\binom{\ell}{p}\binom{k}{q}[\ell-p+2(k-q)]!
(p+2q)!\\
&=\sum_{q=0}^{k}\sum_{p=0}^{\ell}\binom{\ell}{p}\binom{k}{q}[\ell-p+2(k-q)]!
(p+2q)!\\
&= \sum_{q=0}^{k}\sum_{r=2q}^{\ell
+2q}\binom{\ell}{r-2q}\binom{k}{q}(\theta-r)! r!.
\end{split}
\end{equation*}
%
\end{frame}
\begin{frame}
  \frametitle{Main Combinatorial Idea}
Now for each fixed $0\le r \le \theta$ we collect all $q\in
\{0,1,\ldots,k\}$ such that $r-\ell  \le 2q \le r$. Thus, for each
fixed $0\le r \le \theta$ there exist $0\le i_0(r)\le i_1(r)\le k$ such
that
%
\[i_0(r)\le q \le i_1(r).\]
%
%
%
Thus, it follows that
\begin{equation*}
\begin{split}
&\sum_{p=0}^{\ell}
\sum_{q=0}^{k}\binom{\ell}{p}\binom{k}{q}[\ell-p+2(k-q)]!
(p+2q)!\\
&= \sum_{r=0}^\theta \left [\sum_{q=i_0(r)}^{i_1(r)}
\binom{\ell}{r-2q}\binom{k}{q}\right](\theta-r)!
r!.
\end{split}
\end{equation*}
\end{frame}
%
%
\begin{frame}
  \frametitle{Finishing the Proof}
Since
\begin{equation*}
\sum_{r=0}^{\theta}\binom{\theta}{r}r! (\theta-r)! \le
\sum_{r=0}^{\theta}\binom{\theta}{r} r! (\theta-r)!
=(\theta+1)\theta!
\end{equation*}
to complete the proof it is enough to show that
%
\begin{equation*}
 \sum_{
q=i_0(r)}^{i_1(r)}\binom{\ell}{r-2q}\binom{k}{q} \le
\binom{\theta}{r}.
\end{equation*}
%
\end{frame}
%
%
\begin{frame}
%
By using the definition of $\theta$ and the inequality $
\binom{\beta}{\alpha}\binom{\delta}{\gamma}\leq
\binom{\beta+\delta}{\alpha+\gamma},
$
%
we obtain
\begin{equation*}
\begin{split}
 &\sum_{
q=i_0(r)}^{i_1(r)}\binom{\ell}{r-2q}\binom{k}{q}
\\
& \le \sum_{
q=i_0(r)}^{i_1(r)}\binom{\ell +k}{r-2q}
\\
& =\sum_{
q=i_0(r)}^{i_1(r)}\binom{\theta-2k}{r-2q}\\
&=\binom{\theta-2k}{r-2i_0(r)}+\binom{\theta-2k}{r-2(i_0(r)+1)}+\cdots
\\
&+\binom{\theta-2k}{r-2(i_1(r)-2)}+\binom{\theta-2k}{r-2(i_1(r)-1)}
+\binom{\theta-2k}{r-2i_1(r)}.
\end{split}
\end{equation*}
%
\end{frame}
%
%
\begin{frame}
Now, using the following facts
%
$ \binom{a}{b}\le \binom{a+1}{b+1},
$
%
%
$
 \binom{a}{c}\le \binom{b}{c}\,\,\text{if}\,\,a<b,
$
%
 and
%
 $
 \binom{\nu}{\mu}+\binom{\nu}{\mu
+1}=\binom{\nu +1}{\mu +1}
$
we can estimate the sum of the last two terms
\begin{equation*}
\begin{split}
&\binom{\theta-2k}{r-2(i_1(r)-1)} +\binom{\theta-2k}{r-2i_1(r)}=
\binom{\theta-2k}{r-2i_1(r)+2}+\binom{\theta-2k+1}{r-2i_1(r)+1}\\
&\le \binom{\theta-2k+1}{r-2i_1(r)+2}+\binom{\theta-2k+1}{r-2i_1(r)+1}
=\binom{\theta-2k+2}{r-2i_1(r)+2}.
\end{split}
\end{equation*}
%
Repeating this argument $(i_1(r)-i_0(r))$-times we obtain
\begin{equation*}
\begin{split}
&\sum_{ q=i_0(r)}^{i_1(r)}\binom{\ell}{r-2q}\binom{k}{q}\le
\binom{\theta-2k+2(i_1(r)-i_0(r))}{r-2i_0(r)}\le
\binom{\theta-2k+2i_1(r)}{r}\\
&=\binom{\theta-2(k-i_1(r))}{r}\le \binom{\theta}{r},
\end{split}
\end{equation*}
where in the last inequality we have used the fact that $i_1(r)\le
k$. \qed
\end{frame}
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%                appendix proof of anayticity
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
\subsection{Proof of Analyticity Lemma} 
\label{ssec:anal-strip}
\begin{frame}
  \frametitle{Appendix: Proof of Analyticity Lemma}
%
%
  Before proceeding with the proof, we note the following.
  \begin{remark}
Since $\varphi \in G^{\delta,s}(\mathbb{T})$, $s \ge 0$, it follows from the definition of the space $G^{\delta,s}(\mathbb{T})$ that there exists a positive
constant $L$ such that 
\begin{equation}
  \label{suc}
|\hat{\varphi}(n)|\le Le^{-\delta |n|},\,\,\forall\,\,n\in \mathbb{Z}.
\end{equation} 
\end{remark}
To prove the remark, we note that if for some fixed $L$ estimate \eqref{suc} fails
for only finitely many $n_{k}$, then we can choose $L$ sufficiently large such
that \eqref{suc} holds for all $n$. 
\end{frame}
\begin{frame}
  Therefore, fix $L$, and assume that \eqref{suc} fails
for countably many $n_{k}$, that is
%
%
\begin{equation*}
\begin{split}
  |\hat{\varphi}(n_{k})| > Le^{-\delta |n_{k}|}, \quad k \in \mathbb{N}.
\end{split}
\end{equation*}
%
%
%
Then
\begin{equation*}
\begin{split}
 \sum_{n\in \mathbb{Z}} 
 (1+ |n|)^{2s}e^{2\delta|n|}|\widehat{\vp}(n)|^2
 & > \sum_{k \in \mathbb{N}} 
(1+ |n_{k}|)^{2s}e^{2\delta|n_{k}|}L^{2}e^{-2\delta | n_{k} |}
 \\
 & = L^{2} \sum_{k \in \mathbb{N}} (1 + | n_{k} |)^{2s} = \infty, \quad s \ge 0
 \end{split}
\end{equation*}
%
%
which implies $\vp \not \in G^{\delta, s}$. This concludes the proof. \qed
\end{frame}

\begin{frame}
Returning to the proof of the lemma, recall that we can write
\[\varphi(x)=\sum_{n\in \mathbb{Z}}e^{inx}\hat{\varphi}(n).\]
Formally define 
\[\tilde{\varphi}(x+iy)=\sum_{n\in \mathbb{Z}}e^{in(x+iy)}\hat{\varphi}(n)
=\sum_{n\in \mathbb{Z}}e^{inx}e^{-yn}\hat{\varphi}(n).\]
%
%
This definition makes sense for $|y|< \delta$, since by the above remark we have
\begin{eqnarray*}
|\tilde{\varphi}(x+iy)|&\le& \sum_{n\in \mathbb{Z}}e^{-yn}|\hat{\varphi}(n)|
\\
&\le& 
\sum_{n\in \mathbb{Z}}e^{|y| |n|}L e^{-\delta |k|}\\
&=&L \sum_{n\in \mathbb{Z}}e^{-(\delta -|y|) |n|}< \infty
\end{eqnarray*} 
since $|y|< \delta$. 
\end{frame}
\begin{frame}
Furthermore, note that
%
%
\begin{equation*}
\begin{split}
  L \sum_{n \in \mathbb{Z}}| n | e^{-(\delta -|y|) |n|}< \infty
\end{split}
\end{equation*}
%
which implies
\begin{equation*}
\begin{split}
  \infty > \sum_{n \in \mathbb{Z}} i n  e^{in(x + iy)}  \wh{\vp}(n) 
  & = \sum_{n \in \mathbb{Z}} \frac{d}{dz}  e^{in(x + iy)}  \wh{\vp}(n) 
  \\
  & = \frac{d}{dz}\sum_{n \in \mathbb{Z}} e^{in(x + iy)}  \wh{\vp}(n) 
  \\
  & = \frac{d \vp}{dz}
\end{split}
\end{equation*}

%
in the strip $\left\{ x+ iy: | y | < \delta \right\}$. Therefore $\vp$ is
holomorphic there. Also, since $\tilde{\varphi}(x+i0)=\varphi(x)$,
it follows that $\vp$ is real analytic on all of $\ci$.
This completes the proof. \qed
\end{frame}
\end{document}
