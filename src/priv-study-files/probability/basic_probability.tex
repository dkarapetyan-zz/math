\documentclass[12pt]{article}
\usepackage{amsthm}
\usepackage{amssymb} %for symbols like lesssim
\usepackage[showonlyrefs=true]{mathtools} %amsmath extension package
\usepackage[alphabetic, initials, msc-links]{amsrefs} %for the bibliography; uses cite pkg. Must be loaded after hyperref, otherwise doesn't work properly (conflicts with cref in particular)
\usepackage{cancel}  %for cancelling terms explicity on pdf
\usepackage{enumerate} %to change enumerate symbols
\usepackage[margin=2.5cm]{geometry}  %page layout
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=green,
    filecolor=magenta,
    urlcolor=cyan
    linkbordercolor=Blue
    citebordercolor=Violet
    filebordercolor=Red
}
\newcommand{\rr}{\mathbb{R}}
\newcommand{\nn}{\mathbb{N}}
\newcommand{\zz}{\mathbb{Z}}
\newcommand{\cc}{\mathbb{C}}
\newcommand{\ci}{\mathbb{T}}
\newcommand{\dollar}{\$}
\newcommand{\wh}{\widehat}
\newcommand{\p}{\partial}
\newcommand{\ee}{\varepsilon}
\newcommand{\vp}{\varphi}
\newcommand{\wt}{\widetilde}
\newcommand{\filter}{\mathcal{F}}
\newcommand{\prob}{\mathbb{P}}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
\newtheorem*{definition}{Definition}
\newtheorem*{example}{Example}
\newtheorem*{exercise}{Exercise}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\numberwithin{equation}{section}  %eliminate need for keeping track of counters
\begin{document}
\title{Notes on Numerical Computation }
\author{David Karapetyan}
\date{}
\maketitle
\newpage
\setcounter{tocdepth}{2}
\tableofcontents

\newpage
		\section{Outcomes, Events, and Likelihood}
		
		Throughout this course, we seek to rigorously describe the likelihood of
		outcomes of an experiment, or, more generally, combinations of outcomes of an experiment.
		For example, we would like to know the likelihood of the Dodgers
		winning the pennant, or the likelihood that stock of a company will go up
		in a week. We have used words to describe these events--since we are doing
		mathematics, we would like to translate everything to numbers, without losing
		any of the meaning.
	\begin{example}
A fair coin is tossed. There are two possible outcomes: heads (denoted by $0$) 
and tails (denoted by $1$). We call $ \left\{ 0,1 \right\} $ the \emph{outcome
space} or \emph{sample space}. The \emph{event space} consists of
\begin{enumerate}[a)]
\item Outcome is heads or tails
\item Outcome is heads and tails
\item Outcome is heads
\item Outcome is tails
\end{enumerate}
which we translate, via numbers, to the set $ \left\{ \left\{ 0 \right\} \cup
\left\{ 1 \right\}, \left\{ 0 \right\} \cap \left\{ 1 \right\} , \left\{ 0
\right\} , \left\{ 1 \right\} \right \} $
\end{example}	
Observe that the event ``Heads or tails'' is the union of the events
``Outcome is Heads'' and ``Outcome is tails'', and ``Heads and tails'' is
their intersection.
\begin{example}
A die with six distinct faces is thrown. The outcome space is
$ \left\{ 1, 2, 3, 4, 5, 6 \right\} $. Some possible events are
\begin{enumerate}[a)]
\item The outcome is even
\item The outcome is odd
\item The outcome is greater than $2$
\item The outcome is less than $2$.
These events, respectively, are expressed via the sets \\
$ \left\{ 2, 4, 6 \right\} , \left\{ 1,3,5 \right\} , \left\{ 3, 4, 5, 6
\right\}, \left\{ 1 \right\} $.
Observe that there are many other possible outcomes.
\end{enumerate}
\end{example}	
Observe that the larger the outcome space, the more complex
our event space becomes. Also observe that the event
``The outcome is even'' is the \emph{complement} (with respect to the 
outcome space) of
the event ``The outcome is odd''. That is, $ \left\{ 2,4,6 \right\}^c
= \left\{ 1,3,5 \right\} $. 

Motivated by these two examples, we seek to generalize our notion of 
event space such that it completely models all possible events
that can arise from a given outcome space. We have the following.
\begin{definition}
Let $\Omega$ be an outcome space. Then a \emph{$\sigma$-algebra}
on $\Omega$, denoted by $\sigma(\Omega)$ is defined to be a
set of subsets of $\Omega$ that is closed under countable
unions and complements.
More precisely
\begin{enumerate}[a)]
\item $ A_i \in  \sigma \implies \cup_i A_i \in \sigma$
\item $A_i \in \sigma \implies A_i^c \in \sigma$
\end{enumerate}
\end{definition}
\begin{example}
Suppose we are tossing a fair coin repeatedly until the first tail shoes up,
and wish to know the number of tosses we must use. Then our outcome space
is \\ $ \left\{ \left\{ 0 \right\} , \left\{ 0,1 \right\} , \left\{ 0,0,1
\right\},\ldots \right\}$. This is an infinite outcome space.
\end{example}
\begin{example} The following are all $\sigma$-algebras of $\Omega$:
\begin{enumerate}[a)]
\item $\left\{ \emptyset, \Omega \right\}$
\item $\left\{ \emptyset, A, A^c, \Omega \right\}$
\item The power set of $\Omega$
\end{enumerate}
\end{example}
Observe that a natural outcome space to use is the real line, or subsets
thereof, and to build appropriate $\sigma$-algebras on top of it. We will return
to this idea later.

\section{Discrete Probability}
\subsection{Unconditional Probability}
Suppose we roll a $6$-sided die $N$ times. Let $N(A)$ denote the number of $4's$
rolled in $N$ tries. One can observe that
\begin{align*}
\lim_{N \to \infty} N(A)/N = 1/6.
\end{align*}
A similar phenomenon holds for many other real-world events.

\begin{definition}
Let $N(A)$ denote the number of ``successes'' $S$ in $N$ trials . If the
limit $N(A)/N \doteq P$ exists, we say $S$ occurs with probability $P$. 
\end{definition}
Observe that $ 0 \le P \le 1$, by definition. 

Next, let $A$ and $B$ be two disjoint events. Then 
it is easy to check that
\begin{align*}
N(A \cup B) = N(A) + N(B)
\end{align*}
and that, in general (i.e. for possibly disjoint $A$, $B$),
\begin{align*}
N(A \cup B) = N(A) + N(B) - N(A \cap B).
\end{align*}
Furthermore, since $\Omega = A \cup A^c$, it follows immediately
that $N(\Sigma) = N$. A similar argument shows $N(\emptyset) = 0$.
This discussion motivates the following.
\begin{definition}
A \emph{probability measure} on $(\Omega, \filter)$ is a continuous function
$\prob:
\filter \to [0,1]$ which satisfies 
\begin{enumerate}[a)]
	\item
$\prob(\Omega) = 1$, $\prob(\emptyset) = 0$
\item
For disjoint $A_i$, $\prob(\cup_i^n A_i) = \sum_{i = 1}^n \prob(A_i)$.
\end{enumerate}
\end{definition}
Observe that our construction immediately rules out silly probability
measures such as $P \equiv 0$ or $P \equiv 1$. Furthermore,
we can show the following, whose proof we leave to the reader.
\begin{lemma}
Let $\prob$ be a probability measure on $(\Omega, \filter)$
\begin{enumerate}[a)]
\item $\prob(A^c) = 1 - \prob(A)$
\item $\prob(A \cup B) = P(A) + P(B) - P(A \cap B)$.
\item If $B \subset A$, then $P(A) \ge P(B)$.
\item \emph{(Set Continuity)}.
If $\cup_i^\infty A_i = A$ and
$\cap B_i^\infty = B$, with $A_i \subset A_j$ and $B_j \subset B_i$ for $j > i$,
then
\begin{align*}
& \lim \prob(A_i) = \prob(\lim \cup_i^n A_i) = \prob(A) \\
& \lim \prob(B_i) = \prob(\lim \cap_i^n B_i) = \prob(B) \\
\end{align*}
\end{enumerate}
\end{lemma}
A last technical distinction: the empty-set denotes the event ``nothing
occurs'' and has probability $0$, by definition. However, there are many
events in a given sigma-algebra that have probability $0$ but that are not the
empty set. 

\begin{example}What is the probability that, using a fair coin, one
flips only heads in infinitely many tries? Letting $H_N$ denote the event
$N$ heads in the first $N$ tries, set continuity yields
continuity,
\begin{align*}
P(N_\infty) = \lim_{N \to \infty} \prob(N_H) = \lim_{N \to \infty} 2^{-N} = 0.
\end{align*}
\end{example}
\subsection{Conditional Probability}
We now wish to tackle statement that often occur in practice,
such as ``What is the probability that it will snow today, \emph{given}
that the sky is grey today'', or ``What is the probability that a mystery word
is 'zebra', \emph{given} that the first three letters are 'z', 'e', 'b'''.
Observe that when we are given information, it allows us to adjust the
probability of the event we are interested in. We wish to express this
mathematically. Motivated by the ``zebra'' example, we have the following.
\begin{definition}
Let $\Omega, \filter$ be a $\sigma$-algebra, and $A, B \in \filter$ events. 
Then $\prob(A | B)$ is defined to be the probability of $A$, given that $A \in \filter_B$, where $\filter_B
\doteq \left\{ U \in \filter: B \cap U \neq \emptyset \right\}.$
\end{definition}
Imagine that we roll a die, and wish to know the probability that
we have rolled a $4$. 
To compute this, we let $A$ denote the event that we roll a $4$. Then in the last section we saw
that
\begin{align*}
\prob(A) = \lim_{N \to \infty} N(A)/N.
\end{align*}
Suppose now that we are given the event $B$, which is the event that we haven't
rolled a $6$.
What's the probability now that we have rolled a $4$?
Stated a bit differently, how can we modify our ratio above to reflect the
new value? We simply discard all trials whose rolls gave a $6$, as this is clearly
impossible with the new die. Of course, we must also discard the number of times
we rolled a $6$. Putting this all together, we obtain
\begin{align*}
\prob(A | B) & = \lim_{N \to \infty} N(A \cap B)/(N -
\text{number of occurrences of $6$})
\\
& = \lim_{N \to \infty} \frac{N(A \cap B)}{N} \times \frac{1}{1 - (\text{number
of occurrences of $6$)/N}}
\\
& = \frac{\prob(A \cap B)}{(1 - \prob(B^c))}
\\
& = \frac{\prob(A \cap B)}{\prob(B)}.
\end{align*}
Observe that if $\mathbb(B)$
Motivated by this, we have the following definition.
\begin{definition}
Let $A, B$ be events, and suppose $B$ occurs. Then
\begin{align*}
\prob(A | B) \doteq \frac{\prob(A \cap B)}{\prob(B)}
\end{align*}
\end{definition}
Observe that it is implicit in the definition that $\prob(B) > 0$, otherwise
$B$ does not occur.
\begin{example}
A family has two children. What is the probability that both are boys,
given that at least one of them is a boy?
\end{example}
\section{Common Distributions}
\subsection{Bernoulli Distribution}
We begin with the most basic distribution, from which
we are able to derive a multitude of others.
\begin{definition}
Let $X$ be the random variable denoting the number of successes
in $n$ independent trials, where $p$ is the probability of success in 
an individual trial. Then
\begin{equation*}
b(k, n, p) \doteq \mathbb{P}(X = k) = \binom{n}{k} p^k (1 - p)^{n-k}
\end{equation*}
is called the \emph{Bernoulli distribution} of $k$ successes
in $n$ independent trials, where $p$ is the probability of success on an
individual trial. The special case
$p = 1/2$ is called a \emph{binomial distribution}. 
\end{definition}
\begin{example}
Let $X$ denote the number of heads one obtains from $n$ flips of a
two-sided, non-weighted coin. Then $X$ is binomially distributed.
If the coin is weighted, then $X$ follows a Bernoulli distribution.
\end{example}
\subsection{Poisson Distribution}
We wish now to study events that are distributed sparsely in time.
Suppose we have a large number $n$ of independent trials, with
success in each individual trial unlikely. In order to have a sparse
distribution of events that is nontrivial (i.e. we have no successes),
we need to assume that there is a positive
probability that we achieve at least one success in $n$ trials. Hence, we assume the expected number of 
successes $\lambda \doteq np$ to be nonzero. 

Observe that with the above assumptions, we obtain
\begin{equation*}
\binom{n}{k} = \frac{n!}{(n-k)! k!} \approx \frac{n^k}{k!}
\end{equation*}
and so
\begin{align*}
P(X = k)
& = \binom{n}{k} p^k (1 - p)^{n-k} \\
& \approx \frac{n^k p^k q^{n-k}}{k!} \\
& = \frac{\lambda^k q^{n-k}}{k!} \\
& = \frac{\lambda^k (1-p)^{n-k}}{k!} \\
& = \frac{\lambda^k (1-\lambda/n)^{n-k}}{k!} \\
& \approx \frac{\lambda^k (1-\lambda/n)^{n}}{k!} , \quad n >> 1\\
& \approx \frac{\lambda^k e^{-\lambda}}{k!}
\end{align*}
\begin{definition}
We call
\begin{align*}
p(k, \lambda) \doteq \frac{\lambda^k e^{-\lambda}}{k!}
\end{align*}
the \emph{Poisson distribution} of $k$ successes in a large number
of trials, where, on average, we expect $\lambda$ successes, 
where $\lambda$ is much less than the number of trials. 
That is, the trials have the feature that successes are
sparsely distributed.
\end{definition}
We will now extend this result. Assume that in the interval $[0,1]$,
we have $n$ equally spaced points, representing trials. Split this interval into two pieces,
$[0,t]$ and $[t, 1]$. Then we have $nt$ trials in interval $[0,t]$ and
$n - nt$ trials in interval $[t,1]$. Then the average number of successes
in $[0,t]$ is given by $\lambda_t \doteq n t p = \lambda t$. Repeating
our preceding computation, but with $\lambda$ replaced by $\lambda_t$
and $n$ by $nt$, we obtain the following.
\begin{theorem}
Let $\lambda$ be the average number of successes in the interval $[0,1]$.
The probability of finding exactly $k$ successes  in the subinterval $[0,t]$,
$t \le 1$, is given by
\begin{align*}
p(k, \lambda t) = \frac{ (\lambda t)^{k} e^{-\lambda t}}{k!}
\end{align*}
\end{theorem}
\begin{exercise}
Generalize this result to intervals of arbitrary length.
\end{exercise}
\subsection{Negative Binomial Distribution}
For an experiment, it is often important to know just how many trials
one needs to achieve a certain number of successes. To tackle this problem,
we ask a simpler question: out of a total of $n$ independent trials with
either success or failure as the outcome, what is the probability
that the $rth$ success occurs at the $vth$ trial, where $r \le v \le n$?
We reason this out as follows: there is a total of $\binom{v-1}{r-1}$ ways to
arrange $r-1$ successes out of $v-1$ trials, each with associated probability
$p^{r-1}(1 - p)^{(v-1) - (r-1)} = p^{r-1}q^{v-r}$. Right after the $v-1$ trial, we would like to
have the $rth$ success. This success has associated probability $p$. Putting
everything together, we obtain the following.
\begin{theorem}
Let $X$ denote the number of successes achieved after $v$ independent trials of an experiment,
where we assume a success occurs at trial $v$, and where the probability
of success if $p$. Then the probability that $X=r$, where $r \le v$, is given by
\begin{equation*}
p(r, v, p) \doteq \mathbb{P}(X = r) = \binom{v-1}{r-1} p^{r} q^{v-r}
\end{equation*}
\begin{definition}
We call $X$ a random variable with a \emph{negative binomial distribution}.
\end{definition}
\end{theorem}
\end{document}